{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is to test parts of the code in isolation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"raw_sql.csv\", engine=\"pyarrow\")\n",
    "print(\"Data already imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sales_data(data: pd.DataFrame):\n",
    "    \"\"\"Processes the sales data.\n",
    "\n",
    "    This function renames columns, converts date formats, and aggregates quantities by date.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The input dataframe with columns:\n",
    "        \"order_id\",\n",
    "        \"date_created\",\n",
    "        \"fulfilled\",\n",
    "        \"order_items_item_seller_sku\",\n",
    "        \"order_items_quantity\",\n",
    "        \"order_items_unit_price\",\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Processed dataframe with cleaned and aggregated sales data.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    _fail_if_invalid_sales_data(data)\n",
    "\n",
    "    data = _rename_columns(data)\n",
    "    data = _convert_date_column(data)\n",
    "    data = _collapse_sales_data(data)\n",
    "    data = _set_datetime_index(data)\n",
    "    data = _mark_missing_data(data)\n",
    "    data = _remove_long_zero_periods(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def _rename_columns(data: pd.DataFrame):\n",
    "    \"\"\"Renames columns to more understandable names.\"\"\"\n",
    "    return data.rename(\n",
    "        columns={\n",
    "            \"date_created\": \"date\",\n",
    "            \"order_items_quantity\": \"quant\",\n",
    "            \"order_items_unit_price\": \"price\",\n",
    "            \"order_items_item_seller_sku\": \"sku\",\n",
    "        }\n",
    "    ).copy()\n",
    "\n",
    "\n",
    "def _convert_date_column(data: pd.DataFrame):\n",
    "    \"\"\"Converts the 'date' column to datetime format, removes timezones, and normalizes to midnight.\"\"\"\n",
    "    data = data.copy()\n",
    "    # Convert the 'date' column to datetime\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"], errors=\"coerce\")\n",
    "    # Remove timezone: if the timestamp is timezone-aware, use tz_convert(None) to remove the tz info.\n",
    "    data[\"date\"] = data[\"date\"].apply(\n",
    "        lambda x: x.tz_convert(None) if x is not pd.NaT and x.tzinfo is not None else x\n",
    "    )\n",
    "    # Normalize the datetime to midnight (i.e., keep only the date part)\n",
    "    data[\"date\"] = data[\"date\"].dt.normalize()\n",
    "    return data\n",
    "\n",
    "\n",
    "def _collapse_sales_data(data: pd.DataFrame):\n",
    "    \"\"\"Aggregates sales data by date and SKU, summing the quantity and price.\"\"\"\n",
    "    data = data.copy()\n",
    "    # Ensure that the 'date' column is converted to datetime and normalized\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"], errors=\"coerce\").dt.normalize()\n",
    "    # Group by both date and SKU\n",
    "    return data.groupby([\"date\", \"sku\"], as_index=False).agg(\n",
    "        {\"quant\": \"sum\", \"price\": \"sum\"}\n",
    "    )\n",
    "\n",
    "\n",
    "def _set_datetime_index(data: pd.DataFrame):\n",
    "    \"\"\"Sets 'date' as index and converts it to a DatetimeIndex.\"\"\"\n",
    "    data = data.copy()\n",
    "    data = data.set_index(\"date\")\n",
    "    data.index = pd.to_datetime(data.index, errors=\"coerce\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def _mark_missing_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each SKU in the data, reindex the DataFrame so that every day between the first and\n",
    "    last available date is present. For missing days, the \"quant\" and \"price\" values will be\n",
    "    set to 0, while the \"sku\" column will be filled appropriately.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame with a datetime index and a \"sku\" column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Reindexed DataFrame with all days present for each SKU.\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for sku in data[\"sku\"].unique():\n",
    "        sku_data = data[data[\"sku\"] == sku].sort_index()\n",
    "        # Drop rows with invalid (NaT) dates in the index\n",
    "        sku_data = sku_data[sku_data.index.notna()]\n",
    "        if sku_data.empty:\n",
    "            continue\n",
    "\n",
    "        # Normalize the index so that timestamps become midnight\n",
    "        sku_data.index = sku_data.index.normalize()\n",
    "        # Remove duplicate date entries (keeping the first occurrence)\n",
    "        sku_data = sku_data[~sku_data.index.duplicated(keep=\"first\")]\n",
    "\n",
    "        start_date = sku_data.index.min()\n",
    "        end_date = sku_data.index.max()\n",
    "        if pd.isna(start_date) or pd.isna(end_date):\n",
    "            continue\n",
    "\n",
    "        full_date_range = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "        sku_data_reindexed = sku_data.reindex(full_date_range)\n",
    "        # Fill the \"sku\" column for missing days with the current SKU value.\n",
    "        sku_data_reindexed[\"sku\"] = sku\n",
    "        # Fill missing 'quant' and 'price' with 0\n",
    "        sku_data_reindexed[\"quant\"] = sku_data_reindexed[\"quant\"].fillna(0)\n",
    "        sku_data_reindexed[\"price\"] = sku_data_reindexed[\"price\"].fillna(0)\n",
    "        sku_data_reindexed.index.name = \"date\"\n",
    "        df_list.append(sku_data_reindexed)\n",
    "\n",
    "    if df_list:\n",
    "        return pd.concat(df_list)\n",
    "    else:\n",
    "        return data.copy()\n",
    "\n",
    "\n",
    "def _remove_long_zero_periods(\n",
    "    data: pd.DataFrame, zero_period_days: int = 7\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each SKU in the data, for periods where 'quant' is 0 continuously for longer than\n",
    "    zero_period_days, set the 'quant' value to NaN. This indicates that the sales data in that\n",
    "    period is missing or unreliable, so the model can handle it appropriately.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame with a datetime index and a \"sku\" column.\n",
    "        zero_period_days (int): Minimum number of consecutive days with quant equal to 0 to trigger setting to NaN.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with long zero periods marked as missing (NaN).\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for sku in data[\"sku\"].unique():\n",
    "        sku_data = data[data[\"sku\"] == sku].sort_index()\n",
    "        # Create a mask for rows where quant is 0\n",
    "        zero_mask = sku_data[\"quant\"] == 0\n",
    "        zero_data = sku_data[zero_mask]\n",
    "        if zero_data.empty:\n",
    "            df_list.append(sku_data)\n",
    "            continue\n",
    "\n",
    "        # Group consecutive dates in zero_data: if the difference between consecutive dates\n",
    "        # is not exactly one day, then it's a new group.\n",
    "        groups = (zero_data.index.to_series().diff() != pd.Timedelta(days=1)).cumsum()\n",
    "\n",
    "        # For each group of consecutive zeros, if the group is longer than the threshold, mark those rows as missing\n",
    "        for _, group in zero_data.groupby(groups):\n",
    "            if len(group) > zero_period_days:\n",
    "                sku_data.loc[group.index, \"quant\"] = np.nan\n",
    "        df_list.append(sku_data)\n",
    "    if df_list:\n",
    "        return pd.concat(df_list).sort_index()\n",
    "    else:\n",
    "        return data.copy()\n",
    "\n",
    "\n",
    "def _fail_if_invalid_sales_data(data: pd.DataFrame):\n",
    "    \"\"\"Raise an error if data is not a DataFrame or is missing required columns.\"\"\"\n",
    "    required_columns = {\n",
    "        \"order_id\",\n",
    "        \"date_created\",\n",
    "        \"fulfilled\",\n",
    "        \"order_items_item_seller_sku\",\n",
    "        \"order_items_quantity\",\n",
    "        \"order_items_unit_price\",\n",
    "    }\n",
    "\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        error_msg = f\"'data' must be a pandas DataFrame, got {type(data)}.\"\n",
    "        raise TypeError(error_msg)\n",
    "\n",
    "    if not required_columns.issubset(data.columns):\n",
    "        missing_columns = required_columns - set(data.columns)\n",
    "        error_msg = f\"'data' DataFrame is missing required columns: {missing_columns}\"\n",
    "        raise ValueError(error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = process_sales_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries_for_sku(\n",
    "    data: pd.DataFrame, sku: str, start_date: str, end_date: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the time series for a specific SKU between the given start_date and end_date using Plotly,\n",
    "    showing gaps for missing data.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The DataFrame containing sales information with columns including 'sku', 'quant',\n",
    "                             and either a datetime index or a 'date' column.\n",
    "        sku (str): The SKU identifier to filter the data.\n",
    "        start_date (str): The start date of the period (in 'YYYY-MM-DD' format).\n",
    "        end_date (str): The end date of the period (in 'YYYY-MM-DD' format).\n",
    "\n",
    "    Returns:\n",
    "        fig: The Plotly figure object containing the plot.\n",
    "    \"\"\"\n",
    "    # Filter data for the specified SKU\n",
    "    sku_data = data[data[\"sku\"] == sku].copy()\n",
    "\n",
    "    # Ensure the index is datetime; if not, use the 'date' column if available\n",
    "    if not isinstance(sku_data.index, pd.DatetimeIndex):\n",
    "        if \"date\" in sku_data.columns:\n",
    "            sku_data[\"date\"] = pd.to_datetime(sku_data[\"date\"])\n",
    "            sku_data.set_index(\"date\", inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"Data must have a datetime index or a 'date' column.\")\n",
    "\n",
    "    # Filter data for the given time period\n",
    "    mask = (sku_data.index >= start_date) & (sku_data.index <= end_date)\n",
    "    sku_data = sku_data.loc[mask]\n",
    "\n",
    "    # Reindex to include all dates in the period, leaving missing values as NaN\n",
    "    full_date_range = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "    sku_data = sku_data.reindex(full_date_range)\n",
    "    sku_data.index.name = \"date\"\n",
    "    # Fill the 'sku' column for missing rows\n",
    "    sku_data[\"sku\"] = sku\n",
    "\n",
    "    if sku_data.empty:\n",
    "        raise ValueError(\n",
    "            f\"No data found for SKU {sku} between {start_date} and {end_date}.\"\n",
    "        )\n",
    "\n",
    "    # Reset index for Plotly\n",
    "    sku_data_reset = sku_data.reset_index()\n",
    "\n",
    "    # Create a Plotly line chart; missing data (NaN) will create gaps if connectgaps is False\n",
    "    fig = px.line(\n",
    "        sku_data_reset,\n",
    "        x=\"date\",\n",
    "        y=\"quant\",\n",
    "        title=f\"Time Series for SKU {sku} from {start_date} to {end_date}\",\n",
    "        labels={\"date\": \"Date\", \"quant\": \"Quantity\"},\n",
    "    )\n",
    "\n",
    "    # Update traces to not connect gaps\n",
    "    fig.update_traces(connectgaps=False)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku = \"SHIELD\"\n",
    "\n",
    "fig = plot_timeseries_for_sku(clean_data, sku, \"2024-01-01\", \"2025-01-01\")\n",
    "produces = f\"{sku}_time_series.html\"\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
