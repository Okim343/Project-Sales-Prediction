{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"greycom_sales_noOut.xlsx\")\n",
    "\n",
    "# rename columns to something more understandable\n",
    "df.rename(columns={\"DataEmissao\": \"date\", \"Qtd\": \"quant\"}, inplace=True)\n",
    "\n",
    "# convert date column to datetime type\n",
    "df[\"date\"] = pd.to_datetime(df.date)\n",
    "\n",
    "df[\"day_of_week\"] = df[\"date\"].dt.day_name()\n",
    "\n",
    "# df.set_index('date', inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Aggregate the data by SKU and date\n",
    "df_c = df.groupby([\"SKU\", \"date\"], as_index=False).agg({\"quant\": \"sum\"})\n",
    "\n",
    "# Step 2: Convert the 'date' column to datetime format (if it isn't already)\n",
    "df_c[\"date\"] = pd.to_datetime(df_c[\"date\"])\n",
    "\n",
    "# Step 3: Set 'date' as the index\n",
    "df_c.set_index(\"date\", inplace=True)\n",
    "\n",
    "df_c  # this now contains all daily collapsed sales for each SKU, with all dates for the first SKU, then the same for the next and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku = \"TC213\"\n",
    "sku_df = df_c[df_c[\"SKU\"] == sku].copy()\n",
    "\n",
    "# Step 1: Feature Engineering\n",
    "sku_df[\"lag_1\"] = sku_df[\"quant\"].shift(1)\n",
    "sku_df[\"rolling_mean_3\"] = sku_df[\"quant\"].rolling(window=3).mean()\n",
    "sku_df[\"dayofweek\"] = sku_df.index.dayofweek\n",
    "sku_df[\"month\"] = sku_df.index.month\n",
    "sku_df[\"dayofmonth\"] = sku_df.index.day\n",
    "\n",
    "sku_df.dropna(inplace=True)\n",
    "\n",
    "sku_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import contextlib\n",
    "import os\n",
    "\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "\n",
    "# Function to train model and predict future quantities for a specific SKU\n",
    "def predict_for_sku(sku, df, prediction_length=30):\n",
    "    # Filter data for the specific SKU\n",
    "    sku_df = df[df[\"SKU\"] == sku].copy()\n",
    "\n",
    "    # Step 1: Feature Engineering\n",
    "    sku_df[\"lag_1\"] = sku_df[\"quant\"].shift(1)\n",
    "    sku_df[\"rolling_mean_3\"] = sku_df[\"quant\"].rolling(window=3).mean()\n",
    "    sku_df[\"dayofweek\"] = sku_df.index.dayofweek\n",
    "    sku_df[\"month\"] = sku_df.index.month\n",
    "    sku_df[\"dayofmonth\"] = sku_df.index.day\n",
    "\n",
    "    sku_df.dropna(inplace=True)\n",
    "\n",
    "    # Step 2: Train/Test Split\n",
    "    train = sku_df[sku_df.index < \"2024-07-01\"]\n",
    "    test = sku_df[sku_df.index >= \"2024-07-01\"]\n",
    "\n",
    "    feature_columns = [\"lag_1\", \"rolling_mean_3\", \"month\", \"dayofweek\", \"dayofmonth\"]\n",
    "    TARGET = \"quant\"\n",
    "\n",
    "    X_train = train[feature_columns]\n",
    "    y_train = train[TARGET]\n",
    "\n",
    "    X_test = test[feature_columns]\n",
    "    y_test = test[TARGET]\n",
    "\n",
    "    # Step 3: Train the XGBoost Model\n",
    "    reg = xgb.XGBRegressor(\n",
    "        base_score=0.5,\n",
    "        booster=\"gbtree\",\n",
    "        n_estimators=1000,\n",
    "        early_stopping_rounds=50,\n",
    "        objective=\"reg:squarederror\",\n",
    "        max_depth=3,\n",
    "        learning_rate=0.01,\n",
    "    )\n",
    "    with contextlib.redirect_stdout(\n",
    "        open(os.devnull, \"w\")\n",
    "    ):  # gets rid of the verbose when running the model\n",
    "        reg.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            verbose=100,\n",
    "        )\n",
    "\n",
    "    # Step 4: Predict the Future\n",
    "    future_dates = pd.date_range(\n",
    "        start=\"2024-08-01\", periods=prediction_length, freq=\"D\"\n",
    "    )\n",
    "    future_df = pd.DataFrame(index=future_dates)\n",
    "    future_df[\"month\"] = future_df.index.month\n",
    "    future_df[\"dayofweek\"] = future_df.index.dayofweek\n",
    "    future_df[\"dayofmonth\"] = future_df.index.day\n",
    "\n",
    "    # Handling the lag_1 feature initialization\n",
    "    if not test.empty and len(test) > 0:  # Check if the test DataFrame is not empty\n",
    "        future_df[\"lag_1\"] = test[\"quant\"].iloc[\n",
    "            -1\n",
    "        ]  # Use the last value from test DataFrame\n",
    "    else:\n",
    "        if (\n",
    "            not train.empty and len(train) > 0\n",
    "        ):  # Fallback to the last value in train if test is empty\n",
    "            future_df[\"lag_1\"] = train[\"quant\"].iloc[-1]\n",
    "        else:\n",
    "            future_df[\"lag_1\"] = (\n",
    "                0  # Fallback to a default value if both test and train are empty or invalid\n",
    "            )\n",
    "\n",
    "    rolling_window = 3\n",
    "    predictions = []\n",
    "\n",
    "    for date in future_df.index:\n",
    "        # Update rolling mean\n",
    "        if len(predictions) >= rolling_window:\n",
    "            future_df.at[date, \"rolling_mean_3\"] = np.mean(\n",
    "                predictions[-rolling_window:]\n",
    "            )\n",
    "        else:\n",
    "            future_df.at[date, \"rolling_mean_3\"] = np.mean(predictions)\n",
    "\n",
    "        # Ensure features are aligned before prediction\n",
    "        features = future_df.loc[date, feature_columns].values.reshape(1, -1)\n",
    "        prediction = reg.predict(features)\n",
    "        predictions.append(prediction[0])\n",
    "\n",
    "        # Update lag feature for the next prediction\n",
    "        future_df.at[date, \"lag_1\"] = prediction[0]\n",
    "\n",
    "    future_df[\"predicted_value\"] = predictions\n",
    "    future_df[\"SKU\"] = sku\n",
    "\n",
    "    return future_df[[\"predicted_value\", \"SKU\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Loop over all SKUs and store predictions\n",
    "def generate_predictions_all_skus(df, prediction_length=30):\n",
    "    unique_skus = df[\"SKU\"].unique()\n",
    "    all_predictions = pd.DataFrame()\n",
    "\n",
    "    for sku in unique_skus:\n",
    "        sku_predictions = predict_for_sku(sku, df, prediction_length)\n",
    "        all_predictions = pd.concat([all_predictions, sku_predictions])\n",
    "\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Function to retrieve predictions for a specific SKU and plot\n",
    "def get_predictions_for_sku(sku, all_sku_predictions):\n",
    "    sku_predictions = all_sku_predictions[all_sku_predictions[\"SKU\"] == sku]\n",
    "\n",
    "    # Plot the predictions\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(\n",
    "        sku_predictions.index,\n",
    "        sku_predictions[\"predicted_value\"],\n",
    "        label=f\"Predicted for {sku}\",\n",
    "        color=\"r\",\n",
    "    )\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Predicted Quantity\")\n",
    "    plt.title(f\"Predicted Sales for SKU: {sku}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return sku_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for all SKUs\n",
    "all_sku_predictions = generate_predictions_all_skus(df_c)\n",
    "\n",
    "# Example usage to get predictions and plot for a specific SKU\n",
    "\n",
    "\n",
    "sku_to_check = input(\"Please enter the SKU you want to check: \")\n",
    "sku_predictions = get_predictions_for_sku(sku_to_check, all_sku_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_predictions.round()  # for whatever SKU you chose before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_predictions[\"predicted_value\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_predictions_20 = sku_predictions[sku_predictions.index <= \"2024-08-20\"]\n",
    "sku_predictions_20[\"predicted_value\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
